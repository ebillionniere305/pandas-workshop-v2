{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Data Analysis with Pandas & Jupyter, November 2019\n",
    "\n",
    "Workshop lead: Sam Bail [@spbail](http://twitter.com/spbail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The goal of this workshop is to give learners an intro to data analysis with Python using Pandas and Jupyter. \n",
    "We will first go through the process of loading data from CSV files, inspecting and cleaning the data. As a second step, we will analyse the data and draw some insights about cancer treatment from it. \n",
    "\n",
    "The tutorial is structured as follows:\n",
    "\n",
    "- Intro and background\n",
    "- Part 0: Quick Jupyter exercise\n",
    "- Part 1: Loading and inspecting data\n",
    "- Part 2: Data cleaning\n",
    "- Part 3: Data analysis\n",
    "- Part 4: Summary\n",
    "\n",
    "**Note that this tutorial is only intended as an introduction to some basic concepts of Pandas. It is in no means intended to be comprehensive, and there are a lot of useful functions a beginner needs to know to do in-depth data analysis. We hope that this tutorial sets you up for self-guided learning to master the full range of necessary Pandas tools.**\n",
    "\n",
    "## How to follow along with the workshop\n",
    "- You can run every cell in the notebook as we go along using the shortcut Shift+Enter\n",
    "- You will encounter a few <span style=\"color:blue\">*** DIY exercise ***</span> blocks where you'll get a few minutes to try out what you've just learned\n",
    "- Feel free to save and download your notebook from Binder at the end since Binder deletes notebooks after 12 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "## What is Jupyter (and the Jupyter ecosystem...)?\n",
    "- IPython is an interactive Python shell (just type \"ipython\" to start it)\n",
    "- Jupyter is a Python library that provides a web-based UI on top of ipython to create notebooks with code and output\n",
    "- JupyterLab provides some additional features on top of Jupyter, e.g. a file browser\n",
    "- Binder is a web-based hub for containers that contain your Python environment and renders notebooks based on a git repo\n",
    "\n",
    "## What is Pandas/Matplotlib/Pyplot/Seaborn?\n",
    "\n",
    "- Pandas is a Python library for data manipulation and analysis. It offers data structures and operations for manipulating numerical tables and time series.\n",
    "- Matplotlib is a Python 2D plotting library. Pyplot is a collection of command style functions in matplotlib that make matplotlib work like MATLAB. While we mostly use Seaborn, we sometimes fall back to using Pyplot functions for certain aspects of plotting.\n",
    "- Seaborn is a Python data visualization library based on matplotlib. It's kind of like a nicer version of Pyplot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Quick Jupyter exercise (10 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebooks are basically just interactive ipython terminals, intermixed with markdown text:\n",
    "- Cells can be either code or markdown\n",
    "- You can execute any kind of Python code\n",
    "- Variables persist between cells\n",
    "- The notebook doesn't care about the order of cells, just the order of executing it in order to remember variables. However, \"run all\" executes your cells top to bottom.\n",
    "\n",
    "Notebooks have **two modes**: a) editing the cells and b) navigating the notebook (command mode).\n",
    "- You can navigate around the notebook in command mode by clicking cells or using the arrow keys\n",
    "- Depending on the environment you're using (Jupyter notebook, Jupyter lab, Google Colab...) there will be a different visual cue to indicate the mode a cell is in\n",
    "- In order to edit a cell, you can hit enter or double-click it.\n",
    "- To execute the cell content, hit Shift+Enter to run the cell\n",
    "- To get out of edit mode, hit the Escape key\n",
    "\n",
    "Some additional helpful shortcuts:\n",
    "- The default type for a cell is code. In command mode, hit *m* to make a cell markdown and *y* to make it code\n",
    "- Hit *a* in command mode to create a new cell *above* the current one\n",
    "- Hit *b* in command mode to create a new cell *below* the current one\n",
    "- *Tab* autocompletes methods (like in ipython)\n",
    "- *Shift+Tab* shows you the docstring for the outer function of the line your cursor is in\n",
    "- Hit *dd* in command mode to delete a cell. \n",
    "- *Cmd+z* undoes operations in the highlighted cell, *z* undoes cell operations in the notebook (e.g. deleting a cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples\n",
    "\n",
    "print('Hello world!')\n",
    "\n",
    "import math\n",
    "math.ceil(4.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*** DIY exercise ***</span>\n",
    "Try out using only your keyboard and shortcuts for these two tasks:\n",
    "- Create a new *markdown* cell below this one, write a few lines and format them to look like a header and bullets.\n",
    "- Create a new *code* cell above the first one one, import your favorite Python function, check out the docstring, and execute the code (e.g. `os.getcwd()`, `random.random()`, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Loading and inspecting the data (20 mins)\n",
    "\n",
    "Before we can start answering questions about the data we need to do a little bit of exploratory analysis.The first thing we need to do when working with a new dataset is to get an idea of what the data looks like. We start by loading the data into memory. Pandas comes with a built-in `read_csv` function that we can use to read CSV files and load them directly to a pandas `DataFrame` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to import the libraries to start with\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# This command makes charts show inline in a notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Making the figures show up a little larger than default size\n",
    "plt.rcParams['figure.figsize'] = [10,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of different ways to read data into a dataframe - from lists, dicts, CSVs, databases... Here's an example of querying a database table to pull data into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Set up a connection to a public SQL database\n",
    "conn = psycopg2.connect(\"\"\"\n",
    "    host='hh-pgsql-public.ebi.ac.uk' dbname='pfmegrnargs' user='reader' password='NWDMCE5xdipIjRrp'\n",
    "\"\"\")\n",
    "\n",
    "# Write a SQL query to pull the data\n",
    "query = \"SELECT * FROM rnacen.protein_info LIMIT 5\"\n",
    "\n",
    "# Execute the query and store the result in a dataframe\n",
    "df_from_db = pd.read_sql(query, conn)\n",
    "\n",
    "# Show the resulting dataframe\n",
    "df_from_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a DataFrame?\n",
    "A DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects. It is generally the most commonly used Pandas object. \n",
    "\n",
    "Pandas borrows the concept of DataFrame from the statistical programming language R.\n",
    "\n",
    "Let's take a look at the data to familiarize ourselves with the format and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from a CSV into a dataframe\n",
    "# This is the data we're going to be working with!\n",
    "tx = pd.read_csv('./mock_treatment_starts_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We already did this: Just using the name of the dataframe will print the entire output\n",
    "# If there are too many rows, Jupyter will print the top few and bottom few rows\n",
    "# with a \"...\" to indicate that there are more rows\n",
    "tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The head(n) function shows the first n rows in a dataframe.\n",
    "# If no n is specified, it defaults to 5 rows.\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use the sample() function to get n random rows in the dataframe\n",
    "# NOTE: sample() only works in newer versions of pandas (0.16.1 and upwards)\n",
    "tx.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then len function gives us the number of rows in the dataframe\n",
    "len(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dtypes property of a dataframe shows the datatypes of every column in a dataframe.\n",
    "tx.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns attribute of a dataframe contains the column names\n",
    "# We'll talk about the \"Index\" later!\n",
    "tx.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The describe function shows some basic statistics for numeric columns\n",
    "# We only have one here, so this isn't very interesting\n",
    "tx.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*** DIY exercise ***</span>\n",
    "Create a new cell below and print the first ten rows of the \"tx\" dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing columns in a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Note: We will be applying `head()` to some results in this tutorial to keep the output short. When working with a real dataset, keep in mind that you might be hiding some relevant records if you always use `head()` or `sample()`!**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, you can access a specific column using the following notation which returns a **Series** (not a dataframe) - a Series is simply a vector, aka a 1-dimensional data structure similar to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the PatientID column as a Series\n",
    "tx['PatientID'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type to show that this indeed returns a Series object\n",
    "type(tx['PatientID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The alternative notation for accessing a column in a dataframe\n",
    "# Some people prefer the . notation, others the [] notation.\n",
    "# Personally, I prefer using [] for visibility and consistency\n",
    "tx.PatientID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And this is how you access two columns of a dataframe.\n",
    "# Note that this will return a dataframe again, not a series (because a series has only one column...)\n",
    "# Also note the double square brackets - you're passing a *list* of columns as an argument\n",
    "tx[['PatientID', 'Dosage']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type to confirm that this returns a DataFrame type\n",
    "type(tx[['PatientID', 'TreatmentStart']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This way we can now do some more data exploration, e.g. looking at unique patient IDs\n",
    "sorted(tx['PatientID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*** DIY exercise ***</span>\n",
    "Create a new cell below and print the list of unique drugs in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing rows in a dataframe\n",
    "In addition to slicing by column, we often want to get the record where a column has a specific value, e.g. a specific Patient_ID here. This can be done using the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the record(s) for a specific patient ID\n",
    "tx.loc[tx['PatientID'] == 'PT20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is equivalent with the following shorter notation\n",
    "# I prefer to always use loc to be more explicit\n",
    "tx[tx['PatientID'] == 'PT20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use boolean conditions in the selector\n",
    "tx.loc[(tx['PatientID'] == 'PT20') & (tx['Drug'] == 'Cisplatin')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*** DIY exercise ***</span>\n",
    "Create a new cell below and show all rows where the drug dosage for Cisplatin is less than 180."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting dataframes\n",
    "Sorting a dataframe by one or multiple columns is super easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by earliest treatment start date, i.e. in ascending order\n",
    "tx.sort_values('TreatmentStart').head()\n",
    "\n",
    "# NOTE: sort_values only works in Pandas 0.17.0 and up. This is an older version:\n",
    "# tx.sort('TreatmentStart').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by latest treatment start, i.e. in descending order\n",
    "tx.sort_values('TreatmentStart', ascending=False).head()\n",
    "\n",
    "# NOTE: sort_values only works in Pandas 0.17.0 and up. This is an older version:\n",
    "# tx.sort('TreatmentStart', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, you can also sort by a list of column. If you want to change the \n",
    "# ascending/descending orders, pass a list of booleans to the `ascending` parameter!\n",
    "tx.sort_values(['PatientID', 'TreatmentStart']).head()\n",
    "\n",
    "# NOTE: sort_values only works in Pandas 0.17.0 and up. This is an older version:\n",
    "# tx.sort(['PatientID', 'TreatmentStart']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Any operations on a dataframe are *not* permanent, i.e. they only modify the current output, but not the actual dataframe. If you want to preserve the sorting, for example, you have to either assign the output to a new variable, or use the `inplace=True` argument. This will not create any output but actually modify the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dataframe\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the inplace keyword to modify the dataframe\n",
    "# Note that you can also sort by a list of columns\n",
    "tx.sort_values(['PatientID', 'TreatmentStart'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the permanently sorted dataframe\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*** DIY exercise ***</span>\n",
    "Create a new cell below and sort the dataframe by drug (ascending, i.e. alphabetically) and then dosage (descending order, i.e. highest dosage first)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Data cleaning (15 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember the dtypes property... the TreatmentStart column should really be a date, right?\n",
    "tx.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right away we can see that the date field TreatmentDate is stored as string (object). It might be useful to convert it to **Datetime** objects so that we can perform common date arithmetic on them, like checking if a date came before or after another date, or calculating the number of days between two dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assigns the datetime version of the TreatmentStart column to a column with the same name\n",
    "tx['TreatmentStart'] = pd.to_datetime(tx['TreatmentStart'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the types now - we have a datetime64 type!\n",
    "tx.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the alternative notation to access a column in a dataframe\n",
    "tx.TreatmentStart = pd.to_datetime(tx.TreatmentStart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidebar: Copying dataframes\n",
    "Note that if you assign a dataframe to a new variable, it will reference the same underlying object as the original dataframe. This means that any modification you make to the new dataframe will also be applied to the old one. Use the `copy()` function to make a new copy of the dataframe by value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx2 = tx\n",
    "\n",
    "# Create a new dummy column in the \"copy\" of our dataframe\n",
    "tx2['NewColumn'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tx2 now has the new column...\n",
    "tx2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... but so does our original dataframe. This is not really what we want!\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the dummy column from the original dataframe\n",
    "# axis=1 means we're dropping columns, and we need to use inplace=True to make it permanent!\n",
    "if 'NewColumn' in tx.columns:\n",
    "    tx.drop('NewColumn', axis=1, inplace=True)\n",
    "\n",
    "# Then make a real copy of the \"clean\" tx dataframe\n",
    "tx2 = tx.copy()\n",
    "\n",
    "# Add the dummy column to tx2 and confirm that the original tx doesn't have it\n",
    "tx2['NewColumn'] = 1\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*** DIY exercise ***</span>\n",
    "Create a copy of the tx dataframe and add a new column TreatmentStartDT that contains the treatment starts as datetime types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Data analysis (30 minutes)\n",
    "Let's assume we've loaded the treatment related data from a cancer clinic in order to provide them with some analytical insights around the types of drugs they use on their patient population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Patients treated at the practice\n",
    "\n",
    "**How many patients does the practice treat?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data frame contains patient IDs and treatment starts -\n",
    "# let's check if some patients have multiple treatment starts?\n",
    "# The unique() function returns the number of unique values in a dataframe column.\n",
    "print('Number of treatment start records:', len(tx))\n",
    "print('Number of unique patients who start treatment:', len(tx.PatientID.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 20 unique patients but we have 23 treatment starts, meaning some patients start different treatments in the time that we have data for. This means that if we want to answer the question correctly, we need to make sure to only count unique patients. Let's learn some counting techniques first before coming back to the duplicate issue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Drugs used at the practice\n",
    "**What are the drugs used at the practice and how many patients receive those drugs?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx.groupby('Drug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The groupby function works like a groupby in SQL, i.e. it groups the dataframe by the specified\n",
    "# column and then lets you apply aggregate functions on the grouped values, e.g. counts, sums, means...\n",
    "# The count function counts the number of rows with non-null values in a column\n",
    "tx.groupby('Drug').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are only interested in the number of patients, \n",
    "# we select only the relevant column from the resulting dataframe\n",
    "# Note that \"PatientID\" might not be the best name for this column\n",
    "# - we can use a rename() function in Pandas to rename it to something like\n",
    "# \"PatientCount\" (skipping the rename step in this tutorial, but feel free to look it up!)\n",
    "tx.groupby('Drug').count()[['PatientID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use nunique() which counts the number of *unique* non-null values for each column\n",
    "# Notice how the numbers are different from the count() result\n",
    "tx.groupby('Drug').nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*** DIY exercise ***</span>\n",
    "With the techniques you just learned in Question 2, think back to Question 1. Create a new cell below and count how many records each patient has in order to spot those patients that receive more than one treatment.\n",
    "\n",
    "**Additional point to think about:** Depending on what question we want to answer, counting the number of records might not give us the correct answer. Can you think of different questions a clinic might ask to explain why patients have multiple records? What stands out when using nunique() instead of count()?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little bit about indexes in dataframes\n",
    "Notice that in the above example, the \"Drug\" column is printed in bold. That's because grouping by it has turned it into the **index** of the resulting dataframe.\n",
    "\n",
    "The index in a dataframe is the \"row identifier\" - it is generally printed as the column on the left. For example, when we first loaded our data, the index didn't have a name and was just an incrementing integer (scroll up to check!). When you create a groupby object, the index of a resulting dataframe will be the column you group by - in this case, the Drug column became the index.\n",
    "\n",
    "We frequently **reset** the index in a dataframe for various reasons - in this case, because the index contains data that you want to treat as a column, e.g. for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same groupby we did above. Notice how the \"Drug\" column is bold\n",
    "# - it became the index after grouping by it\n",
    "tx.groupby('Drug').count()[['PatientID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index in the grouped dataframe to see what happens:\n",
    "tx.groupby('Drug').count()[['PatientID']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that any operations on the dataframe only modify the output? \n",
    "# We didn't *really* group the dataframe or reset the index. \n",
    "# The tx dataframe is still the same it was at the beginning.\n",
    "# We could use inplace=True to make the change permanent.\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's plot this! (aka our first Seaborn plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do the same groupby as above to get the number of patient starts per drug.\n",
    "# This time, we actually assign the output to a new dataframe `counts` to make the change permanent.\n",
    "counts = tx\\\n",
    "    .groupby('Drug')\\\n",
    "    .count()[['PatientID']]\\\n",
    "    .reset_index()\n",
    "\n",
    "# Let's use a simple bar chart in Seaborn to compare counts for the two drugs\n",
    "# There are several different ways to do the plotting - this is my preferred style,\n",
    "# but you might prefer different syntax\n",
    "fig = sns.barplot(data=counts, x='Drug', y='PatientID')\n",
    "plt.title('Number of patient starts by drug')\n",
    "plt.ylabel('Number of patient starts')\n",
    "plt.xlabel('Drug')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Changes to treatment over time\n",
    "**Do we see any changes in treatment patterns over time?**\n",
    "\n",
    "Our data shows treatment starts by date. Let's group these starts by month to see if there are any changes of how many patients start on a given drug over time, e.g. because a new drug got approved.\n",
    "\n",
    "*Note that the data we're using here is dummy data and pretty artificial - oncology clinics see a much higher volume of patients, and drug uptake is usually slower than shown here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add a new column that only has the treatment month to simplify things\n",
    "# There are many different ways to do this, we picked a simple one\n",
    "tx['TreatmentStartMonth'] = tx['TreatmentStart'].astype('datetime64[M]')\n",
    "\n",
    "# NOTE .astype('datetime64[M]') only works in more recent versions of Pandas, this is an older version:\n",
    "# from datetime import datetime\n",
    "# tx['TreatmentStartMonth'] = tx['TreatmentStart'].apply(lambda x: x.replace(day=1))\n",
    "\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count the number of starts per month per drug to plot it later\n",
    "# We only want the number of patients, so we filter for that column at the end\n",
    "drugs_by_month = tx.groupby(['TreatmentStartMonth', 'Drug']).count()[['PatientID']]\n",
    "drugs_by_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data already looks interesting... let's plot this \n",
    "# Remember to reset_index so we can plot the regular columns\n",
    "# The \"hue\" keyword is generally used to distinguish two different categorical variables\n",
    "# in plots, e.g. in this case the two different drugs\n",
    "# NOTE: lineplot() only exists in Seaborn version 0.9 and up\n",
    "fig = sns.lineplot(data=drugs_by_month.reset_index(), \n",
    "                   x='TreatmentStartMonth', \n",
    "                   y='PatientID',\n",
    "                   hue='Drug')\n",
    "plt.title('Number of patient starts by drug and by month')\n",
    "plt.ylabel('Number of patient starts')\n",
    "plt.xlabel('Drug')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*** DIY exercise ***</span>\n",
    "Plot drugs_by_month as a clustered barplot instead of lineplot. Make sure you're clear about what your x, y, and hue are in this case!\n",
    "\n",
    "Note that the date labeling on the x axis doesn't look good because Seaborn converts the month back to a datetime. There are several ways to deal with this - can you think of one possible solution that works in this particular case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Question 4: Dosage and outliers\n",
    "**Question: What is the average dosage of each drug? Are there any outliers?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An easy first step is to group by the respective drug and use describe()\n",
    "tx.groupby(['Drug']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of a more complex way to get aggregates in Pandas\n",
    "# The agg function takes a dictionary of column:function pairs,\n",
    "# where \"function\" can be a built-in function like count, mean, min, etc, \n",
    "# or a custom function like a lambda.\n",
    "tx.groupby(['Drug']).agg({'Dosage': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also pass a list of functions to a column to get multiple outputs!\n",
    "tx.groupby(['Drug']).agg({'Dosage': ['count', 'mean', 'std', 'min', 'max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot this easily in Seaborn - but the outlier squashes our display\n",
    "fig = sns.boxplot(data=tx, x='Drug', y='Dosage')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use showfliers=False in a boxplot to suppress outliers\n",
    "fig = sns.boxplot(data=tx, x='Drug', y='Dosage', showfliers=False)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Summary!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hope this workshop was useful for you. We've only touched on some of the basic concepts of pandas, but we believe this will give you the foundations to keep exploring the data! We covered:\n",
    "\n",
    "- Basic operations in Jupyter and data loading with Pandas\n",
    "- Dataframes and Series in pandas\n",
    "- Basic data inspection (head, describe, dtypes, accessing columns and rows, sorting)\n",
    "- Grouping and aggregating (count, nunique)\n",
    "- Indexing in dataframes and reset_index\n",
    "- Plotting (bar plots, line plots)\n",
    "\n",
    "**What we didn't learn:**\n",
    "\n",
    "This is my (biased) list of very frequent Pandas operations that we didn't cover but you'll likely need for data analysis:\n",
    "- Joining/merging multiple dataframes\n",
    "- Filtering and de-duplicating dataframes\n",
    "- More complex modifications of column values, e.g. filling null values, using lambda functions\n",
    "- More complex aggregates on grouped dataframes (sum, mean, etc)\n",
    "- Renaming columns (e.g. renaming an aggregate \"PatientID\" column to something more meaningful like \"PatientCount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me know what you think! samanthapbail@gmail.com / [@spbail](http://twitter.com/spbail)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
